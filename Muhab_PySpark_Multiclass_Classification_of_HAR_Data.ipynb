{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3f03d5c0",
      "metadata": {
        "id": "3f03d5c0"
      },
      "source": [
        "# Multiclass Classification of HAR Data\n",
        "- <b> HAR stands for Human Activity Recognition<b>.\n",
        "- Human activities such as sit, stand, walk, ... etc. can be measured using cell phones\n",
        "and smart watch sensors.\n",
        "- One of these senseros is the <b>accelerometer</b>.\n",
        "- The given data contains x,y, and z accelerometer readings\n",
        "as well as, cell phone model and device (we have more than one device of the same model).\n",
        "- The target label is the column named <b>gt</b>.\n",
        "- The target label contains <b>6</b> different human activities.\n",
        "\n",
        "## The Objective is:\n",
        "### To build a classifier to predict human activity (gt) from the input features.\n",
        "    \n",
        "#### Please follow the following steps:\n",
        "1. Read the <b>MoreReduced_Phones_accel_cleaned.csv</b> file.\n",
        "2. Show the <b>Schema</b> of the data.\n",
        "3. Remove the first column and keep the others (x,y,z,User,Model,Device,gt)\n",
        "4. Display the summary statistics of the data.\n",
        "5. Check for null in each column.\n",
        "6. If the data contains null drop the rows that contain null values.\n",
        "7. Display the count of each class.\n",
        "8. Train/Test split with 70% Train and 30% test.\n",
        "Use <b>Stratified Sampling</b> to obtain a balanced ratios of classes.\n",
        "<b>You can use the code below</b>.\n",
        "9. Perform the required features engineering.\n",
        "10. Use any classifier of your choice.\n",
        "11. Create a <b>Pipeline</b> that contains all feature engineering steps and the classifier.\n",
        "12. Train the <b>Pipeline Model</b> using trainig data.\n",
        "13. Evaluate the <b>Pipeline Model</b> using test data <b>(use f1-score)</b>.\n",
        "14. As long as HAR data is not easy to classify, <b>the required f1-score should not less\n",
        "    than 0.4</b>."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rbd2s1eMKe2",
        "outputId": "7a967565-3b46-49aa-f747-0ba7e940babe"
      },
      "id": "4Rbd2s1eMKe2",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "07UKpljsK_8P"
      },
      "id": "07UKpljsK_8P",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "6WKiBkApLBwu",
        "outputId": "530142ce-8803-40e9-997b-c33fcdd00d3c"
      },
      "id": "6WKiBkApLBwu",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ed1c2114827f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AqC5tcRMLM04",
        "outputId": "d50ab5da-5d9d-4bbb-8fc8-ded899876a52"
      },
      "id": "AqC5tcRMLM04",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>pre { white-space: pre !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1-Read the MoreReduced_Phones_accel_cleaned.csv file."
      ],
      "metadata": {
        "id": "zDJ-GoAUM3ai"
      },
      "id": "zDJ-GoAUM3ai"
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv('/content/drive/MyDrive/MoreReduced_Phones_accel_cleaned.csv',header=True,inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9B5OgVtLMyP",
        "outputId": "c8859e2b-a342-40a5-e726-311d59a31d25"
      },
      "id": "Z9B5OgVtLMyP",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "|   _c0|         x|                  y|                z|User|     Model|      Device| gt|\n",
            "+------+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "| 75757|  0.766135|-0.9193620000000001|         9.959755|   a|samsungold|samsungold_1|  1|\n",
            "|124359|-5.1510773|        -0.75042725|         6.159439|   b|    nexus4|    nexus4_2|  2|\n",
            "| 18271|-6.0142345|        0.095768064|7.690175999999999|   a|        s3|        s3_1|  4|\n",
            "| 40271|-6.2247925|         0.05607605|7.952057000000001|   a|    nexus4|    nexus4_1|  4|\n",
            "|  7355| -3.370994|           1.072589|         7.048442|   b|samsungold|samsungold_2|  3|\n",
            "+------+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-Show the Schema of the data."
      ],
      "metadata": {
        "id": "O9n8zsYVNav8"
      },
      "id": "O9n8zsYVNav8"
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJRf8b1OLMvg",
        "outputId": "554ca0c3-5748-4e9c-a2b7-fcca91e99931"
      },
      "id": "WJRf8b1OLMvg",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- x: double (nullable = true)\n",
            " |-- y: double (nullable = true)\n",
            " |-- z: double (nullable = true)\n",
            " |-- User: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Device: string (nullable = true)\n",
            " |-- gt: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3-Remove the first column and keep the others (x,y,z,User,Model,Device,gt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "44eZPKtfNhSp"
      },
      "id": "44eZPKtfNhSp"
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.select(\"x\", \"y\", \"z\", \"User\", \"Model\", \"Device\", \"gt\")"
      ],
      "metadata": {
        "id": "uadxzY0xLMtD"
      },
      "id": "uadxzY0xLMtD",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAT8sZYNLMpz",
        "outputId": "5ac2b39f-6664-4be6-89ea-eadfcc244d83"
      },
      "id": "NAT8sZYNLMpz",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "|         x|                  y|                z|User|     Model|      Device| gt|\n",
            "+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "|  0.766135|-0.9193620000000001|         9.959755|   a|samsungold|samsungold_1|  1|\n",
            "|-5.1510773|        -0.75042725|         6.159439|   b|    nexus4|    nexus4_2|  2|\n",
            "|-6.0142345|        0.095768064|7.690175999999999|   a|        s3|        s3_1|  4|\n",
            "|-6.2247925|         0.05607605|7.952057000000001|   a|    nexus4|    nexus4_1|  4|\n",
            "| -3.370994|           1.072589|         7.048442|   b|samsungold|samsungold_2|  3|\n",
            "+----------+-------------------+-----------------+----+----------+------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-Display the summary statistics of the data."
      ],
      "metadata": {
        "id": "-22r1lumOOb_"
      },
      "id": "-22r1lumOOb_"
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwLCLWy0ON-u",
        "outputId": "11bd9e90-5bc8-4831-92f7-9de98ca826bb"
      },
      "id": "YwLCLWy0ON-u",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------------------+-------------------+-----+----------+------------+------------------+\n",
            "|summary|                  x|                  y|                  z| User|     Model|      Device|                gt|\n",
            "+-------+-------------------+-------------------+-------------------+-----+----------+------------+------------------+\n",
            "|  count|              40944|              40944|              40944|40944|     40944|       40944|             40944|\n",
            "|   mean|-1.6171014976873441|0.14958031448959583|   8.90737169789521| null|      null|        null|2.5647469714732316|\n",
            "| stddev| 3.9526104137374483| 1.5492538575847232| 2.2600429846372188| null|      null|        null|1.7549087875346667|\n",
            "|    min|-27.202834999999997|         -11.015778|-1.9919509999999998|    a|    nexus4|    nexus4_1|                 0|\n",
            "|    max| 15.475926999999999|           9.346847| 28.749159999999996|    i|samsungold|samsungold_2|                 5|\n",
            "+-------+-------------------+-------------------+-------------------+-----+----------+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5-Check for null in each column."
      ],
      "metadata": {
        "id": "olS3B_JNOZ5m"
      },
      "id": "olS3B_JNOZ5m"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXHFdH7ON8K",
        "outputId": "523475f2-46bc-42d8-d628-e7958862cd36"
      },
      "id": "tCXHFdH7ON8K",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+----+-----+------+---+\n",
            "|  x|  y|  z|User|Model|Device| gt|\n",
            "+---+---+---+----+-----+------+---+\n",
            "|  0|  0|  0|   0|    0|     0|  0|\n",
            "+---+---+---+----+-----+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6-If the data contains null drop the rows that contain null values."
      ],
      "metadata": {
        "id": "wzT-nKwZO6dD"
      },
      "id": "wzT-nKwZO6dD"
    },
    {
      "cell_type": "code",
      "source": [
        "#No NULL Values\n",
        "#df = df.dropna()"
      ],
      "metadata": {
        "id": "5b7yHUjVON5R"
      },
      "id": "5b7yHUjVON5R",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7-Display the count of each class."
      ],
      "metadata": {
        "id": "niWTneO3PJqG"
      },
      "id": "niWTneO3PJqG"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "df.groupBy(\"gt\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0WuYbJbON2v",
        "outputId": "fd7d2a55-9c31-4525-f1b3-d8bc15470874"
      },
      "id": "U0WuYbJbON2v",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| gt|count|\n",
            "+---+-----+\n",
            "|  1| 7258|\n",
            "|  3| 6500|\n",
            "|  5| 7957|\n",
            "|  4| 6725|\n",
            "|  2| 5784|\n",
            "|  0| 6720|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8-Train/Test split with 70% Train and 30% test. Use Stratified Sampling to obtain a balanced ratios of classes. You can use the code below."
      ],
      "metadata": {
        "id": "Zi6ZoepTPwrp"
      },
      "id": "Zi6ZoepTPwrp"
    },
    {
      "cell_type": "code",
      "source": [
        "gt_distinct = df.select('gt').distinct().collect()\n",
        "\n",
        "train_Df = df.sampleBy('gt',fractions={gt_distinct[i]['gt']: 0.7\n",
        "                                       for i in range(len(gt_distinct))},seed=1)\n",
        "\n",
        "test_DF = df.subtract(train_Df)"
      ],
      "metadata": {
        "id": "d8mDRkMvON0C"
      },
      "id": "d8mDRkMvON0C",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-Perform the required features engineering."
      ],
      "metadata": {
        "id": "rgjXVlu7QYbO"
      },
      "id": "rgjXVlu7QYbO"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder"
      ],
      "metadata": {
        "id": "B5PAsVJwSjq8"
      },
      "id": "B5PAsVJwSjq8",
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = [\"x\", \"y\", \"z\"]\n",
        "cat_cols = [\"User\", \"Model\", \"Device\"]"
      ],
      "metadata": {
        "id": "Wytdh2NZYUm2"
      },
      "id": "Wytdh2NZYUm2",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexers = [\n",
        "    StringIndexer(inputCol=column, outputCol=f\"{column}_index\", handleInvalid=\"keep\")\n",
        "    for column in cat_cols\n",
        "]"
      ],
      "metadata": {
        "id": "VySur73lcf8p"
      },
      "id": "VySur73lcf8p",
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"x\", \"y\", \"z\",\"User_index\", \"Model_index\", \"Device_index\"],\n",
        "    outputCol=\"features\"\n",
        ")"
      ],
      "metadata": {
        "id": "_cstFxpXbFcY"
      },
      "id": "_cstFxpXbFcY",
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_indexer = StringIndexer(inputCol=\"gt\", outputCol=\"label\")"
      ],
      "metadata": {
        "id": "mSjt9x0KcBxQ"
      },
      "id": "mSjt9x0KcBxQ",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10-Use any classifier of your choice."
      ],
      "metadata": {
        "id": "zsolcE2zg_BK"
      },
      "id": "zsolcE2zg_BK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trying Logistic Regression"
      ],
      "metadata": {
        "id": "50WP9EifhBLl"
      },
      "id": "50WP9EifhBLl"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "classifier = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "0bH5l8zMe86c"
      },
      "id": "0bH5l8zMe86c",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11-Create a Pipeline that contains all feature engineering steps and the classifier.\n",
        "##12-Train the Pipeline Model using trainig data.\n",
        "##13-Evaluate the Pipeline Model using test data (use f1-score)."
      ],
      "metadata": {
        "id": "vUYCQAHJhfa-"
      },
      "id": "vUYCQAHJhfa-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler,label_indexer, classifier])"
      ],
      "metadata": {
        "id": "bZv6F7KUONs_"
      },
      "id": "bZv6F7KUONs_",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the pipeline model\n",
        "model = pipeline.fit(train_Df)"
      ],
      "metadata": {
        "id": "UH6m1YMATJy4"
      },
      "id": "UH6m1YMATJy4",
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_DF)"
      ],
      "metadata": {
        "id": "U6GsKGNMTJhI"
      },
      "id": "U6GsKGNMTJhI",
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# Evaluate the predictions using the F1 score\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HGDBKDMU8g3",
        "outputId": "f4d23de3-39bc-434b-c9d5-e13b3be2f6b0"
      },
      "id": "1HGDBKDMU8g3",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.32399046303143997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The F1 Score is less Than 0.40 so we will try another Model"
      ],
      "metadata": {
        "id": "TDBbUBBjhpdT"
      },
      "id": "TDBbUBBjhpdT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trying Random Forest"
      ],
      "metadata": {
        "id": "Lfnd9e28h3fs"
      },
      "id": "Lfnd9e28h3fs"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=42)"
      ],
      "metadata": {
        "id": "YT4BeBPLU0N6"
      },
      "id": "YT4BeBPLU0N6",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler,label_indexer, classifier])"
      ],
      "metadata": {
        "id": "tZ6lhNOOd6ha"
      },
      "id": "tZ6lhNOOd6ha",
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the pipeline model\n",
        "model = pipeline.fit(train_Df)"
      ],
      "metadata": {
        "id": "QXY_ZSYzd6Xz"
      },
      "id": "QXY_ZSYzd6Xz",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_DF)"
      ],
      "metadata": {
        "id": "wLuEUMsigrLH"
      },
      "id": "wLuEUMsigrLH",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the predictions using the F1 score\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHHUVYpSgrFc",
        "outputId": "eaba8e8a-06f0-4578-824c-abfdcad34438"
      },
      "id": "xHHUVYpSgrFc",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.4889686067533028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##14-As long as HAR data is not easy to classify, the required f1-score should not less than 0.4."
      ],
      "metadata": {
        "id": "md5nArhNiKDh"
      },
      "id": "md5nArhNiKDh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The F1_score is better than 0.40"
      ],
      "metadata": {
        "id": "w4b5GQkpiQ6W"
      },
      "id": "w4b5GQkpiQ6W"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lvIqA0dMi3DE"
      },
      "id": "lvIqA0dMi3DE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}